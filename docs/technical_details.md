# 実装の概要

`train_pix2pix.py` では U-Net ジェネレータと PatchGAN 識別器を組み合わせた pix2pix モデルを実装しています。主な特徴は以下の通りです。

- **多層 VGG Perceptual Loss**: `relu1_2` から `relu4_3` までの中間特徴を利用し、細部の再現性を向上。
- **CosineAnnealingLR** による学習率調整。
- **PSNR / SSIM** を計測し、学習過程の品質を数値で把握。
- 混合精度学習 (`torch.cuda.amp`) と勾配累積によるメモリ効率化。
- SciPy を用いた**太さシフト増強**をオプションで利用可能。
- ジェネレータ／識別器の正規化に **InstanceNorm** を選択できる。
- `log_memory` オプションで各エポック後に GPU メモリ消費量を表示。
- YAML 設定ファイルを読み込む `train_from_config` を用意。
- Stage2 では `rehearsal_ratio` により既存文字を混合し、データセットバランスを保てる。
- 生成画像は FontForge などでトレースしてベクトル化可能。
- `train_pix2pix_pro.py` で 256px 事前学習と 512px ファインチューニングを連続実行可能。
- 学習対象文字は外部ファイルから読み込むか、フォント内の非空白グリフのみを自動抽出可能。

学習スクリプトはフォント画像ペアを自動生成し、指定エポックごとにチェックポイントやサンプル画像を保存します。
